{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfCx_f-V1D-a",
    "outputId": "d19a3a67-0d43-4d44-93ba-2a589cdcbc2e"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9lQcKt-GqJr",
    "outputId": "74d897e5-1ea8-49d1-e1c3-a3e7fa69e71d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from termcolor import colored\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_PATH = os.path.dirname(os.path.abspath(\"../../Classes\"))\n",
    "if not (CLASSES_PATH in sys.path):\n",
    "    sys.path.append(CLASSES_PATH)\n",
    "from Classes.Files_Handler_Class import Files_Handler\n",
    "from Classes.Bcolors_Class import Bcolors as bcolors\n",
    "from Classes.Average_Meter_Class import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_centrality = ['layer_density','layer_degree_histogram','layer_edge_weight',\n",
    "                    'layer_sombor_index', 'layer_nodes_weight','layer_k_shell_weight']\n",
    "node_centrality = ['degree', 'clustering', 'nip', 'sombor_index', 'ego_density','ego_degree',\n",
    "                     'ego_k_shell', 'ego_degree_mean','kss', 'vote_power']\n",
    "drop_centrality = ['layer_id', 'node_id', 'weight', 'k_shell', 'k_shell_itr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_AdeP_ShSMR",
    "outputId": "59edef80-c4fe-45db-df23-e708276e3104"
   },
   "outputs": [],
   "source": [
    "best_train_model = False\n",
    "loaded_model = '' \n",
    "loaded_node_layer_embedding_model = '' \n",
    "loaded_optimizer = '' \n",
    "data_path = ''\n",
    "''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eIcpsUkKcg33"
   },
   "outputs": [],
   "source": [
    "def get_content_of_csv_files(path: \"str\", files_list: \"list\", drop_culm:list[str]=[]):\n",
    "    content_list = []\n",
    "    for item in files_list:\n",
    "        content_list.append(pd.read_csv(str(path + item)))\n",
    "        content_list[-1] = content_list[-1].drop(drop_culm, axis=1)\n",
    "        null_values = content_list[-1].isnull().sum()\n",
    "        null_row_cunt = null_values.sum()\n",
    "        if null_row_cunt > 0:\n",
    "            print(item, null_row_cunt)\n",
    "            for j, jtem in enumerate(null_values):\n",
    "                if jtem > 0 :\n",
    "                    print(list(content_list[-1])[j], jtem)\n",
    "        content_list[-1] = content_list[-1].dropna()\n",
    "    return content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wU9N7cKIcg34",
    "outputId": "ad3b2156-189d-4692-8be2-9a793c7d0898"
   },
   "outputs": [],
   "source": [
    "select_file_object = Files_Handler()\n",
    "multiple_selecion = False\n",
    "\n",
    "data_path = select_file_object.select_files(\"text files\", \".csv\", multiple_selecion)\n",
    "path = \"\"\n",
    "networks_content = []\n",
    "\n",
    "if multiple_selecion:\n",
    "    path = data_path[0][:data_path[0].rfind(\"/\")] + \"/\"\n",
    "    for item in data_path:\n",
    "        networks_content.append(pd.read_csv(item))\n",
    "else:\n",
    "    path = data_path[:data_path.rfind(\"/\")] + \"/\"\n",
    "    networks_name = select_file_object.get_files_in_path(path,'csv')\n",
    "    networks_content = get_content_of_csv_files(path, networks_name)\n",
    "print(len(networks_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvMfQRTe09HB",
    "outputId": "4fd1a953-319a-400b-d0cb-38d566852ffd"
   },
   "outputs": [],
   "source": [
    "load_model_status = False\n",
    "loaded_model = select_file_object.select_files(\"Model file\", \".pt\", False)\n",
    "loaded_lr, loaded_wd, loaded_epochs = None, None, None\n",
    "if loaded_model != '':\n",
    "    loaded_model_info = select_file_object.get_file_path_info(loaded_model)\n",
    "    if best_train_model:\n",
    "      loaded_lr = float(loaded_model_info['name'].split(\" \")[2].split(\"=\")[1])\n",
    "      loaded_wd = float(loaded_model_info['name'].split(\" \")[3].split(\"=\")[1])\n",
    "      loaded_epochs = int(loaded_model_info['name'].split(\" \")[4].split(\"=\")[1])\n",
    "    else:\n",
    "      loaded_lr = float(loaded_model_info['name'].split(\" \")[2].split(\"=\")[1])\n",
    "      loaded_wd = float(loaded_model_info['name'].split(\" \")[3].split(\"=\")[1])\n",
    "      loaded_epochs = int(loaded_model_info['name'].split(\" \")[4].split(\"=\")[1])\n",
    "\n",
    "    load_model_status = True\n",
    "if load_model_status:\n",
    "  print(bcolors.OKGREEN + f\"Load model: {load_model_status}\" + bcolors.ENDC)\n",
    "  print()\n",
    "  print(bcolors.OKBLUE + loaded_model_info['path']+ bcolors.ENDC)\n",
    "  print(bcolors.WARNING + loaded_model_info['name']+ bcolors.ENDC)\n",
    "  print()\n",
    "  print(bcolors.OKGREEN + f\"loaded_lr: {loaded_lr}\"  + bcolors.ENDC)\n",
    "  print(f\"loaded_wd: {loaded_wd}\")\n",
    "  print(bcolors.FAIL + f\"loaded_epochs: {loaded_epochs}\" + bcolors.ENDC)\n",
    "else:\n",
    "   print(bcolors.FAIL + f\"Load model: {load_model_status}\" + bcolors.ENDC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1KT6MLOXcg34"
   },
   "outputs": [],
   "source": [
    "data = pd.concat(networks_content, axis=0)\n",
    "del networks_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = data['SIR'].values\n",
    "data = data.drop(['SIR','class_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[node_centrality].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[layer_centrality].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "alpha = 0.5\n",
    "for i, item in enumerate(node_centrality):\n",
    "    j =  i + 1\n",
    "    while j < (len(node_centrality) -1):\n",
    "        _,p_value = stats.ttest_ind(a=data[item].values, b=data[node_centrality[j]].values, equal_var=False)\n",
    "        if p_value > alpha:\n",
    "            print(bcolors.FAIL + item + \" -> \" + node_centrality[j]+ \": \" + str(p_value) + bcolors.ENDC)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(frac = 1) # Shuffle data\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# data_scaled = std_scaler.fit_transform(data.to_numpy())\n",
    "# data_scaled = pd.DataFrame(data_scaled, columns=[node_centrality + layer_centrality])\n",
    "\n",
    "# data = data_scaled\n",
    "\n",
    "# data_min = data.min()\n",
    "# data_max = data.max()\n",
    "# data_scaled = (data-data_min)/(data_max-data_min)\n",
    "\n",
    "# data = data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcUoF0GVcg35",
    "outputId": "ecc326ee-825f-493f-f45d-8a95c04085d0"
   },
   "outputs": [],
   "source": [
    "layer_x_data = data[layer_centrality].values\n",
    "node_x_data = data[node_centrality].values\n",
    "\n",
    "print(bcolors.OKBLUE + f\"Node Data: {node_x_data.shape}\" + bcolors.ENDC)\n",
    "print(bcolors.FAIL + f\"Layer Data: {layer_x_data.shape}\" + bcolors.ENDC)\n",
    "print(bcolors.OKGREEN + f\"SIR Data: {y_data.shape}\" + bcolors.ENDC)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei9urVSqcg36",
    "outputId": "396b98e0-b917-40ed-e270-88e4b160f532"
   },
   "outputs": [],
   "source": [
    "node_x_data = torch.FloatTensor(node_x_data)\n",
    "layer_x_data = torch.FloatTensor(layer_x_data)\n",
    "y_data = torch.FloatTensor(y_data)\n",
    "\n",
    "print(bcolors.OKBLUE + f\"Node Data: {node_x_data.shape}\" + bcolors.ENDC)\n",
    "print(bcolors.FAIL + f\"Layer Data: {layer_x_data.shape}\" + bcolors.ENDC)\n",
    "print(bcolors.OKGREEN + f\"Ground Truth: {y_data.shape}\" + bcolors.ENDC)\n",
    "# node_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXNRfnbGcg37",
    "outputId": "ff02c032-0988-4fa6-caec-938e4c247b28"
   },
   "outputs": [],
   "source": [
    "(node_x_train, node_x_test,\n",
    "layer_x_train, layer_x_test,\n",
    "y_train, y_test) = train_test_split(node_x_data, layer_x_data, y_data,\n",
    "                                    train_size=0.8, shuffle=True, random_state=64)\n",
    "\n",
    "if True:\n",
    "    print(bcolors.OKBLUE + \"Node Data:\")\n",
    "    print(\"  Train: \" + str(node_x_train.shape))\n",
    "    print(\"  Test:  \"  + str(node_x_test.shape) + bcolors.ENDC)\n",
    "    print()\n",
    "    print(bcolors.FAIL + \"Layer Data:\")\n",
    "    print(\"  Train: \" + str(layer_x_train.shape))\n",
    "    print(\"  Test:  \" + str(layer_x_test.shape) + bcolors.ENDC)\n",
    "    print()\n",
    "    print(bcolors.OKGREEN + \"Ground Truth:\")\n",
    "    print(\"  Train: \" + str(y_train.shape))\n",
    "    print(\"  Test:  \" + str(y_test.shape) + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlY3sHDj09HD",
    "outputId": "10eeecaf-81f0-481c-a739-bfbb016e9eb8"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "node_mu = node_x_train.mean(dim=0)\n",
    "node_std = node_x_train.std(dim=0)\n",
    "print(bcolors.OKGREEN + \"node_mu:\\n    \" + bcolors.ENDC + str(node_mu) + '\\n')\n",
    "print(bcolors.OKGREEN + \"node_std:\\n    \" + bcolors.ENDC  + str(node_std) + '\\n\\n')\n",
    "\n",
    "node_x_train = (node_x_train - node_mu) / node_std\n",
    "node_x_test = (node_x_test - node_mu) / node_std\n",
    "#-------------------------------------------------------------\n",
    "layer_mu = layer_x_train.mean(dim=0)\n",
    "layer_std = layer_x_train.std(dim=0)\n",
    "print(bcolors.FAIL + \"layer_mu:\\n   \" + bcolors.ENDC + str(layer_mu) + '\\n')\n",
    "print(bcolors.FAIL + \"layer_std:\\n   \" + bcolors.ENDC + str(layer_std) )\n",
    "\n",
    "layer_x_train = (layer_x_train - layer_mu) / layer_std\n",
    "layer_x_test = (layer_x_test - layer_mu) / layer_std\n",
    "#-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tYiQWytscg37"
   },
   "outputs": [],
   "source": [
    "del node_x_data, layer_x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4ix2pBxWcg37"
   },
   "outputs": [],
   "source": [
    "train_set = TensorDataset(node_x_train, layer_x_train, y_train)\n",
    "test_set = TensorDataset(node_x_test, layer_x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dkpEL5rocg37"
   },
   "outputs": [],
   "source": [
    "del node_x_train, layer_x_train, y_train, node_x_test, layer_x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "RAGTrc0Pcg37"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNSwKyftcg38",
    "outputId": "1663cebd-4437-45f8-a945-1b5bf21d8d91"
   },
   "outputs": [],
   "source": [
    "node_x, layer_x, y = next(iter(train_loader))\n",
    "print(bcolors.OKBLUE + \"Node data shape   . . . . : \" + str(node_x.shape) + bcolors.ENDC)\n",
    "print(bcolors.FAIL + \"Layer data shape  . . . . : \" + str(layer_x.shape) + bcolors.ENDC)\n",
    "print(bcolors.OKGREEN + \"Ground Truth data shape . : \" + str(y.shape) + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "krx4P9TScg38"
   },
   "outputs": [],
   "source": [
    "class Node_Embedding_Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, node_in_features: int, node_out_features: int,\n",
    "        bias: bool, activation: nn.modules.activation, device: str = \"cpu\",\n",
    "        h0:int = 8, h1: int = 16, h2: int = 32, h3: int = 64, h4: int = 128, h5 = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.node_embeding = nn.Sequential(\n",
    "            nn.Linear(in_features=node_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=node_out_features, bias=bias, device=device)\n",
    "        )\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(in_features=node_out_features, out_features=1, bias=False, device=device),\n",
    "        )\n",
    "\n",
    "    def forward(self, node_x):\n",
    "        node_y = self.node_embeding(node_x).unsqueeze(dim=1)\n",
    "        y = self.regression(node_y)\n",
    "        return y\n",
    "   \n",
    "class Node_Layer_Embedding_Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, node_in_features: int, node_out_features: int,\n",
    "        layer_in_features: int, layer_out_features: int,        \n",
    "        bias: bool, activation: nn.modules.activation, device: str = \"cpu\",\n",
    "        h0:int = 8, h1: int = 16, h2: int = 32, h3: int = 64, h4: int = 128, h5 = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.node_embeding = nn.Sequential(\n",
    "            nn.Linear(in_features=node_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=node_out_features, bias=bias, device=device)\n",
    "        )\n",
    "        self.layer_embeding = nn.Sequential(\n",
    "            nn.Linear(in_features=layer_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=layer_out_features, bias=bias, device=device)\n",
    "            )\n",
    "        \n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(in_features=node_out_features, out_features=1, bias=False, device=device),\n",
    "        )\n",
    "\n",
    "    def forward(self, node_x, layer_x):\n",
    "        node_y = self.node_embeding(node_x).unsqueeze(dim=2)\n",
    "        layer_y = self.layer_embeding(layer_x).unsqueeze(dim=1)\n",
    "        y = torch.matmul(node_y, layer_y)\n",
    "        y = torch.mean(y, dim=1)\n",
    "        y = self.regression(y)\n",
    "        return y\n",
    "\n",
    "class Multilayer_Full_Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, node_in_features: int, node_out_features: int,\n",
    "        layer_in_features: int, layer_out_features: int,\n",
    "        encoder_head: int, num_encoder:int, encoder_activation: str,\n",
    "        bias: bool, dropout: float,\n",
    "        activation: nn.modules.activation, device: str = \"cpu\",\n",
    "        h0:int = 8, h1: int = 16, h2: int = 32, h3: int = 64, h4: int = 128, h5 = 256\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.node_embedding = nn.Sequential(\n",
    "            nn.Linear(in_features=node_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=node_out_features, bias=bias, device=device)\n",
    "        )\n",
    "       \n",
    "        self.node_embedding_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=node_out_features, nhead=encoder_head,\n",
    "                dim_feedforward=(4 * node_out_features), dropout=dropout,\n",
    "                activation=encoder_activation, bias=bias,\n",
    "                batch_first=True, device=device),\n",
    "            1)\n",
    "\n",
    "        self.layer_embedding = nn.Sequential(\n",
    "            nn.Linear(in_features=layer_in_features, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=layer_out_features, bias=bias, device=device)\n",
    "            )\n",
    "        \n",
    "        self.layer_embedding_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=node_out_features, nhead=encoder_head,\n",
    "                dim_feedforward=(4 * node_out_features), dropout=dropout,\n",
    "                activation=encoder_activation, bias=bias,\n",
    "                batch_first=True, device=device),\n",
    "            1)\n",
    "        \n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=node_out_features, nhead=encoder_head,\n",
    "                dim_feedforward=(4 * node_out_features), dropout=dropout,\n",
    "                activation=encoder_activation, bias=bias,\n",
    "                batch_first=True, device=device),\n",
    "            num_encoder)\n",
    "       \n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(in_features=node_out_features, out_features=h4, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h4, out_features=h3, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h3, out_features=h2, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h2, out_features=h1, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h1, out_features=h0, bias=bias, device=device),\n",
    "            activation,\n",
    "            nn.Linear(in_features=h0, out_features=1, bias=bias, device=device),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, node_x, layer_x):\n",
    "        node_y = self.node_embedding(node_x)\n",
    "        node_y = torch.matmul(node_y.unsqueeze(dim=2), node_y.unsqueeze(dim=1))\n",
    "        node_y = self.node_embedding_encoder(node_y)\n",
    "        node_y = torch.mean(node_y, dim=1)\n",
    "\n",
    "        layer_y = self.layer_embedding(layer_x)\n",
    "        layer_y = torch.matmul(layer_y.unsqueeze(dim=2), layer_y.unsqueeze(dim=1))\n",
    "        layer_y = self.layer_embedding_encoder(layer_y)\n",
    "        layer_y = torch.mean(layer_y, dim=1)\n",
    "\n",
    "        y = torch.matmul(layer_y.unsqueeze(dim=2), node_y.unsqueeze(dim=1))\n",
    "        y = self.encoder(y)\n",
    "        y = torch.mean(y, dim=1)\n",
    "        y = self.regression(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model ():\n",
    "    node_in_features, node_out_features = 10, 256\n",
    "    layer_in_features, layer_out_features = 6, 256\n",
    "    encoder_head, num_encoder = 32, 2\n",
    "    bias, dropout = True, 0.05\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    return Multilayer_Full_Model(\n",
    "                    node_in_features=node_in_features, node_out_features=node_out_features,\n",
    "                    layer_in_features=layer_in_features, layer_out_features=layer_out_features,\n",
    "                    encoder_head=encoder_head, num_encoder=num_encoder, encoder_activation='gelu',\n",
    "                    bias=bias, dropout=dropout,\n",
    "                    activation=nn.GELU(), device=device).to(device)\n",
    "    \n",
    "if load_model_status:\n",
    "    model = torch.load(loaded_model, map_location=torch.device(device))    \n",
    "    print(bcolors.OKGREEN + 'Model load' + bcolors.ENDC)\n",
    "else:\n",
    "    model = create_model()\n",
    "    print(bcolors.FAIL + 'Model create' + bcolors.ENDC)\n",
    "\n",
    "model_location = next(model.parameters()).is_cuda\n",
    "if model_location:\n",
    "    print(bcolors.OKGREEN + \"Model on GPU.\" + bcolors.ENDC)\n",
    "else:\n",
    "    print(bcolors.FAIL + \"Model on CPU.\" + bcolors.ENDC)\n",
    "\n",
    "def num_params(model):\n",
    "  nums = sum(p.numel() for p in model.parameters()) / 1000\n",
    "  return nums\n",
    "print(\"Number of Model parameters: \", num_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not load_model_status:\n",
    "#     try:\n",
    "#         node_layer_embedding_model = torch.load(loaded_node_layer_embedding_model, map_location=torch.device(device))\n",
    "#         print(bcolors.OKGREEN + 'Node Layer Embedding Model load' + bcolors.ENDC)\n",
    "#     except:\n",
    "#         node_layer_embedding_model_path = select_file_object.select_files(\"text files\", \".pt\", False)\n",
    "#         node_layer_embedding_model = torch.load(node_layer_embedding_model_path, map_location=torch.device(device))\n",
    "    \n",
    "#     pretrained_node_state_dict = node_layer_embedding_model.node_embeding.state_dict()\n",
    "#     pretrained_layer_state_dict = node_layer_embedding_model.layer_embeding.state_dict()\n",
    "#     model.node_embeding.load_state_dict(pretrained_node_state_dict)\n",
    "#     model.layer_embeding.load_state_dict(pretrained_layer_state_dict)\n",
    "#     for param in model.node_embeding.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.layer_embeding.parameters():\n",
    "#         param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F86fvF9Ncg3-",
    "outputId": "7da3a25e-d9ae-4d02-f289-7cff2dddfa54"
   },
   "outputs": [],
   "source": [
    "node_x_batch, layer_x_batch, y_batch = next(iter(train_loader))\n",
    "outputs = model(node_x_batch.to(device), layer_x_batch.to(device)).squeeze(dim=1)\n",
    "print('output shape: ', outputs.shape)\n",
    "print('y shape:      ', y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMCtvTBA1nC7",
    "outputId": "ce8d3fbb-6ad6-4c11-d496-11e462af824f"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.HuberLoss()\n",
    "loss = loss_fn(outputs.to(device), y_batch.to(device))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IvP7YS3Ucg3_"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader:DataLoader,\n",
    "                    loss_fn:nn.modules.activation, optimizer:torch.optim,\n",
    "                    epoch:int=None, device:str='cuda'):\n",
    "  model.train()\n",
    "  loss_train = AverageMeter()\n",
    "  with tqdm(train_loader, unit=\" batch\") as tepoch:\n",
    "    for node_inputs, layer_inputs, targets in tepoch:\n",
    "      if epoch is not None:\n",
    "        tepoch.set_description(f\"Train Epoch {epoch + 1}\")\n",
    "      node_inputs = node_inputs.to(device)\n",
    "      layer_inputs = layer_inputs.to(device)\n",
    "      # targets = targets.to(device)\n",
    "\n",
    "      outputs = model(node_inputs, layer_inputs).squeeze(dim=1)\n",
    "      loss = loss_fn(outputs.to(device), targets.to(device))\n",
    "      # print(loss)\n",
    "\n",
    "      loss.backward()\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss_train.update(loss.item())\n",
    "      tepoch.set_postfix(loss=loss_train.avg)\n",
    "  return model, loss_train.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cGbEZbSccg3_"
   },
   "outputs": [],
   "source": [
    "def validation(model, test_loader:DataLoader,\n",
    "               loss_fn:nn.modules.activation, epoch:int=None, device:str='cuda'):\n",
    "  model.eval()\n",
    "  with tqdm(test_loader, unit=\" batch\") as tepoch:\n",
    "    with torch.no_grad():\n",
    "      loss_valid = AverageMeter()\n",
    "      # acc_valid = Accuracy().to(device)\n",
    "      for node_inputs, layer_inputs, targets in tepoch:\n",
    "        if epoch is not None:\n",
    "          tepoch.set_description(f\"Test  Epoch {epoch + 1}\")\n",
    "        node_inputs = node_inputs.to(device)\n",
    "        layer_inputs = layer_inputs.to(device)\n",
    "        # targets = targets.to(device)\n",
    "\n",
    "        outputs = model(node_inputs, layer_inputs).squeeze(dim=1)\n",
    "        loss = loss_fn(outputs.to(device), targets.to(device))\n",
    "\n",
    "        loss_valid.update(loss.item())\n",
    "        tepoch.set_postfix(loss=loss_valid.avg)\n",
    "        # acc_valid(outputs, targets.int())\n",
    "  return loss_valid.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = 0.0001\n",
    "best_wd = 1e-5\n",
    "delta = -1\n",
    "# if loaded_optimizer == '':\n",
    "#   num_epochs = 3\n",
    "#   for lr in [0.01, 0.009, 0.007, 0.005, 0.003, 0.001, 0.0009, 0.0007, 0.0005, 0.0003, 0.0001]:\n",
    "#     for wd in [1e-4, 1e-5, 0.]:\n",
    "#       model = create_model().to(device)\n",
    "#       optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "#       print(f'LR={lr}, WD={wd}')\n",
    "#       start_loss = torch.inf\n",
    "#       end_loss = torch.inf\n",
    "#       for epoch in range(num_epochs):\n",
    "#         model, loss, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch, device)\n",
    "#         if epoch == 0:\n",
    "#           start_loss = loss\n",
    "#         else:\n",
    "#           end_loss = loss\n",
    "#         if (start_loss - end_loss) > delta:\n",
    "#           delta = start_loss - end_loss\n",
    "#           best_lr = lr\n",
    "#           best_wd = wd\n",
    "#       print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = best_lr\n",
    "wd = best_wd\n",
    "if loaded_optimizer != '':\n",
    "    optimizer = torch.load(loaded_optimizer, map_location=torch.device(device))\n",
    "    print(bcolors.OKGREEN + 'Optimizer load' + bcolors.ENDC)\n",
    "else:\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr, weight_decay=wd)\n",
    "    print(bcolors.FAIL + 'Optimizer create' + bcolors.ENDC)\n",
    "\n",
    "lr = optimizer.param_groups[0]['lr']\n",
    "wd = optimizer.param_groups[0]['weight_decay']\n",
    "print(\"lr = \" + str(lr), \"\\nwd = \" + str(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpWORcfu1nC8",
    "outputId": "35f1f588-3363-4579-e169-dbb3f843616a"
   },
   "outputs": [],
   "source": [
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "epoch_counter = 0\n",
    "best_loss_train = torch.inf\n",
    "best_loss_valid = torch.inf\n",
    "if load_model_status:\n",
    "    loss_train_hist = np.loadtxt(loaded_model_info['path'] + 'highest_epoch_loss_train_hist.txt').tolist()\n",
    "    best_loss_train = min(loss_train_hist[315:])\n",
    "    loss_valid_hist = np.loadtxt(loaded_model_info['path'] + 'highest_epoch_loss_valid_hist.txt').tolist()\n",
    "    best_loss_valid = min(loss_valid_hist[315:])\n",
    "    epoch_counter += len(loss_valid_hist)\n",
    "\n",
    "print(len(loss_train_hist), len(loss_valid_hist))\n",
    "print(best_loss_train, best_loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf-UeYtl09HJ",
    "outputId": "c1c56e16-92ef-4399-b526-7283bb4582b3"
   },
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "model_date = (str(current_date.year) + \"_\" + str(current_date.month) + \"_\" +\n",
    "               str(current_date.day) + \"_\" + str(current_date.hour) + \"_\" +\n",
    "               str(current_date.minute))\n",
    "if load_model_status:\n",
    "    source_code_path = loaded_model_info['path'][:-1][:loaded_model_info['path'][:].rfind(\"/\")]\n",
    "else:\n",
    "    source_code_path = select_file_object.make_dir(str(os.getcwd()), '/Multilayer_Full_Model_Local')\n",
    "source_code_path = source_code_path.replace(\"\\\\\", \"/\")\n",
    "print(source_code_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "clyBZPJ_A5gX"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "loaded_epoch_counter = len(loss_valid_hist)\n",
    "model_info =  (\"model lr=\" + str(lr) + \" wd=\" + str(wd))\n",
    "optimizer_info =  (\"Adam lr=\" + str(lr) + \" wd=\" + str(wd))\n",
    "source_code_path = select_file_object.make_dir(source_code_path, str('/' + str(model_date)) + ' ' + model_info)\n",
    "source_code_path = source_code_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "saved_mode = None\n",
    "saved_mode_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "qE0dscQPcg3_",
    "outputId": "ea07fd39-d2af-45c3-9025-0cca7337913e"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.HuberLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Train\n",
    "  model, loss_train = train_one_epoch(model, train_loader,\n",
    "                                       loss_fn, optimizer, epoch, device)\n",
    "  # Validation\n",
    "  loss_valid = validation(model, test_loader, loss_fn, epoch, device)\n",
    "\n",
    "  loss_train_hist.append(loss_train)\n",
    "  loss_valid_hist.append(loss_valid)\n",
    "  epochs_info = \" epochs=\" + str(epoch + 1 + loaded_epoch_counter) + \" \"\n",
    "\n",
    "  if loss_train < best_loss_train:\n",
    "    if not(saved_mode_train is None):\n",
    "      os.remove(saved_mode_train)\n",
    "    saved_mode_train = (str(source_code_path + \"best_loss_train \" + model_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') +\".pt\"))\n",
    "    torch.save(model, saved_mode_train)\n",
    "    saved_opimizer_train = (str(source_code_path + \"best_loss_train \" + optimizer_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') +\".optim\"))\n",
    "    torch.save(optimizer, saved_opimizer_train)\n",
    "    np.savetxt((source_code_path + 'loss_train_hist.txt'), loss_train_hist)\n",
    "    np.savetxt((source_code_path + 'loss_valid_hist.txt'), loss_valid_hist)\n",
    "    best_loss_train = loss_train\n",
    "    print(bcolors.OKGREEN + f'Train: Loss = {loss_train:.5}' + bcolors.ENDC)\n",
    "  else:\n",
    "    print(bcolors.FAIL + f'Train: Loss = {loss_train:.5}' + bcolors.ENDC)\n",
    "\n",
    "  if loss_valid < best_loss_valid:\n",
    "    if not(saved_mode is None):\n",
    "      os.remove(saved_mode)\n",
    "    saved_mode = (str(source_code_path + 'best_loss_valid ' + model_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') +\".pt\"))\n",
    "    torch.save(model, saved_mode)\n",
    "    saved_opimizer_train = (str(source_code_path + \"best_loss_valid \" + optimizer_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') +\".optim\"))\n",
    "    torch.save(optimizer, saved_opimizer_train)\n",
    "    np.savetxt((source_code_path + 'loss_train_hist.txt'), loss_train_hist)\n",
    "    np.savetxt((source_code_path + 'loss_valid_hist.txt'), loss_valid_hist)\n",
    "    best_loss_valid = loss_valid\n",
    "    print(bcolors.OKGREEN + f'Valid: Loss = {loss_valid:.5}' + bcolors.ENDC)\n",
    "  else:\n",
    "    print(bcolors.FAIL + f'Valid: Loss = {loss_valid:.5}' + bcolors.ENDC)\n",
    "\n",
    "  print()\n",
    "  saved_mode_train = (str(source_code_path + \"highest_epoch_train \" + model_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') +\".pt\"))\n",
    "  torch.save(model, saved_mode_train)\n",
    "  saved_opimizer_train = (str(source_code_path + \"highest_epoch_train \" + optimizer_info + epochs_info +\n",
    "                     ' loss_valid=' + str(f'{loss_valid:.5}') +\n",
    "                     ' loss_train=' + str(f'{loss_train:.5}') + \".optim\"))\n",
    "  torch.save(optimizer, saved_opimizer_train)\n",
    "  np.savetxt((source_code_path + 'highest_epoch_loss_train_hist.txt'), loss_train_hist)\n",
    "  np.savetxt((source_code_path + 'highest_epoch_loss_valid_hist.txt'), loss_valid_hist)\n",
    "  epoch_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "TnvCrQGocg4A",
    "outputId": "22f7acf3-cc05-4df8-f0c9-74c6a95b50cb"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "plt.plot(range(epoch_counter), loss_train_hist, \"r-\", label=\"Train\")\n",
    "plt.plot(range(epoch_counter), loss_valid_hist, \"b-\", label=\"Validation\")\n",
    "\n",
    "plt.xlabel(\"Epoch: \" + str(epoch_counter))\n",
    "plt.ylabel(\"loss: \"\n",
    "           + \"T=\" + str(f\"{loss_train_hist[-1]:.4}\")\n",
    "           + \" & \"\n",
    "           + \"V=\" + str(f\"{loss_valid_hist[-1]:.4}\")\n",
    ")\n",
    "x_spacing = 25\n",
    "y_spacing = 5\n",
    "x_minorLocator = MultipleLocator(x_spacing)\n",
    "y_minorLocator = MultipleLocator(y_spacing)\n",
    "plt.grid(visible=True, alpha=0.8, linewidth=1)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.yaxis.label.set_fontsize('large')\n",
    "ax.xaxis.label.set_fontsize('large')\n",
    "ax.yaxis.set_minor_locator(y_minorLocator)\n",
    "ax.xaxis.set_minor_locator(x_minorLocator)\n",
    "ax.grid(which = 'minor')\n",
    "plt.savefig(\n",
    "    path\n",
    "    + \"epoch=\" + str(len(loss_valid_hist))\n",
    "    + \" loss_valid=\" + str(f\"{loss_valid_hist[-1]:.5}\")\n",
    "    + \" loss_train=\" + str(f\"{loss_train_hist[-1]:.5}\")\n",
    "    + \".png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
