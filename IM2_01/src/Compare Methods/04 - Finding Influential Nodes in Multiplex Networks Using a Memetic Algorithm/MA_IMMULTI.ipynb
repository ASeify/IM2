{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "# import easygui as eui\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_PATH = os.path.dirname(os.path.abspath('../Classes/'))\n",
    "if not (CLASSES_PATH in sys.path):\n",
    "    sys.path.append(CLASSES_PATH)\n",
    "from Classes.Files_Handler_Class import Files_Handler\n",
    "from Classes.Resd_Network_Infos_Class import Resd_Network_Infos\n",
    "from Classes.SIR_Diffusion_Model_Class import SIR_Diffusion_Model\n",
    "from Classes.Get_Past_Results_Class import Get_Past_Results\n",
    "from Classes.Network_Infos_Writer_Class import Network_Infos_Writer\n",
    "from Classes.Memetic_Class import Memetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_size_list = [[1, 2, 3, 4, 5, 6, 8, 10]]\n",
    "datasets_list = ['04 - Irvine (1663 Node and 51 Layer)/Irvine.edgeslist']\n",
    "\n",
    "root_file_path = 'D:/Masters thesis/Methods For Compare/Datasets/'\n",
    "\n",
    "\n",
    "color_list = [\"light_red\", \"light_green\", \"light_yellow\",\n",
    "                    \"light_blue\",\"light_magenta\", \"light_cyan\",\n",
    "                    \"blue\", \"red\", \"white\", \"green\", \"yellow\",\n",
    "                        \"magenta\", \"cyan\", ]\n",
    "tqdm_color_list = ['blue', 'red', 'green', 'cyan', 'magenta', 'yellow', 'black', 'white']\n",
    "\n",
    "\n",
    "files_handler_obj = Files_Handler()\n",
    "SIR_diffusion_model_obj = SIR_Diffusion_Model()\n",
    "resd_network_infos_obj = Resd_Network_Infos()\n",
    "memetic_obj = Memetic()\n",
    "\n",
    "\n",
    "source_code_path = str(os.getcwd())\n",
    "source_code_path = source_code_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "draw_status = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05 - Wainwright/Wainwright.edges 1\n",
      "Wainwright \n",
      "\n",
      "\u001b[92mLayer 1: 43 Node And 42 Edge\u001b[0m\n",
      "\u001b[93mLayer 2: 121 Node And 124 Edge\u001b[0m\n",
      "\u001b[94mLayer 3: 117 Node And 157 Edge\u001b[0m\n",
      "\u001b[95mLayer 4: 44 Node And 48 Edge\u001b[0m\n",
      "\u001b[96mLayer 5: 131 Node And 231 Edge\u001b[0m\n",
      "\u001b[34mLayer 6: 55 Node And 101 Edge\u001b[0m\n",
      "\u001b[31mLayer 7: 76 Node And 49 Edge\u001b[0m\n",
      "\u001b[97mLayer 8: 107 Node And 182 Edge\u001b[0m\n",
      "\u001b[32mLayer 9: 4 Node And 2 Edge\u001b[0m\n",
      "\u001b[33mLayer 10: 120 Node And 162 Edge\u001b[0m\n",
      "\u001b[35mLayer 11: 104 Node And 152 Edge\u001b[0m\n",
      "\u001b[36mLayer 12: 57 Node And 46 Edge\u001b[0m\n",
      "\u001b[91mLayer 13: 136 Node And 210 Edge\u001b[0m\n",
      "\u001b[92mLayer 14: 21 Node And 15 Edge\u001b[0m\n",
      "\u001b[93mLayer 15: 42 Node And 31 Edge\u001b[0m\n",
      "\u001b[94mLayer 16: 73 Node And 69 Edge\u001b[0m\n",
      "\u001b[95mLayer 17: 69 Node And 87 Edge\u001b[0m\n",
      "\u001b[96mLayer 18: 12 Node And 6 Edge\u001b[0m\n",
      "\u001b[34mLayer 19: 73 Node And 59 Edge\u001b[0m\n",
      "\u001b[31mLayer 20: 2 Node And 1 Edge\u001b[0m\n",
      "\u001b[97mLayer 21: 105 Node And 118 Edge\u001b[0m\n",
      "\u001b[32mLayer 22: 73 Node And 66 Edge\u001b[0m\n",
      "\u001b[33mLayer 23: 65 Node And 60 Edge\u001b[0m\n",
      "\u001b[35mLayer 24: 25 Node And 14 Edge\u001b[0m\n",
      "\u001b[36mLayer 25: 100 Node And 92 Edge\u001b[0m\n",
      "\u001b[91mLayer 26: 8 Node And 4 Edge\u001b[0m\n",
      "\u001b[92mLayer 27: 96 Node And 104 Edge\u001b[0m\n",
      "\u001b[93mLayer 28: 67 Node And 64 Edge\u001b[0m\n",
      "\u001b[94mLayer 29: 16 Node And 10 Edge\u001b[0m\n",
      "\u001b[95mLayer 30: 79 Node And 72 Edge\u001b[0m\n",
      "\u001b[96mLayer 31: 21 Node And 15 Edge\u001b[0m\n",
      "\u001b[34mLayer 32: 42 Node And 23 Edge\u001b[0m\n",
      "\u001b[31mLayer 33: 41 Node And 33 Edge\u001b[0m\n",
      "\u001b[97mLayer 34: 12 Node And 7 Edge\u001b[0m\n",
      "\u001b[32mLayer 35: 86 Node And 76 Edge\u001b[0m\n",
      "\u001b[33mLayer 36: 26 Node And 17 Edge\u001b[0m\n",
      "\n",
      "network entier nodes : \u001b[33m217\u001b[0m\n",
      "\u001b[93mRunning generation 1th ...\u001b[0m\n",
      "\u001b[94mcrossover ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58/60 [00:00<00:00, 58142.84 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91mmutation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 122.51 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mLocal search ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:03<00:00, 36.52 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93mspreading_approximation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:07<00:00, 47.55 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[93mRunning generation 2th ...\u001b[0m\n",
      "\u001b[94mcrossover ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58/60 [00:00<?, ? Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91mmutation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 116.89 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mLocal search ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:03<00:00, 35.92 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93mspreading_approximation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:09<00:00, 35.80 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[93mRunning generation 3th ...\u001b[0m\n",
      "\u001b[94mcrossover ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58/60 [00:00<00:00, 57866.23 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91mmutation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 103.23 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mLocal search ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:07<00:00, 14.90 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93mspreading_approximation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:15<00:00, 21.68 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[93mRunning generation 4th ...\u001b[0m\n",
      "\u001b[94mcrossover ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58/60 [00:00<00:00, 58746.59 Gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91mmutation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 78.73 Gen/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mLocal search ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 75/112 [00:06<00:03, 11.27 Gen/s]"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(datasets_list):\n",
    "    file_path = root_file_path + path\n",
    "    for item in seed_size_list[i]:\n",
    "        print(path, item)\n",
    "        seed_set_size = item\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        if file_path is None or file_path == '':\n",
    "            sys.exit(\"File Selection Canceled !\")\n",
    "        file_info = files_handler_obj.get_file_path_info(file_path)\n",
    "        network_name = file_info['name']\n",
    "        network_type = file_info['type']\n",
    "        network_path = file_info['path']\n",
    "        if network_name == \"\":\n",
    "            sys.exit(\"Dont Network Selection!\")\n",
    "        file_info\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        get_past_results_obj = Get_Past_Results(file_info['path'], file_info['name'])\n",
    "        network_infos_writer_obj = Network_Infos_Writer(file_info['path'], file_info['name'])\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        (\n",
    "            network_layers_info,\n",
    "            network_layers_nodes,\n",
    "            entra_layer_edges,\n",
    "            entra_layer_edges_features,\n",
    "            inter_layer_edge,\n",
    "        ) = resd_network_infos_obj.read_nodeFrom_layerFrom_nodeTo_layerTo(\n",
    "            network_path, network_name, network_type\n",
    "        )\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        print(file_info['name'], '\\n')\n",
    "        sum_of_layers_nodes = 0\n",
    "        network_layers_count = len(network_layers_info)\n",
    "        graphs_of_network = [None] * network_layers_count\n",
    "        network_entier_edges = \"\"\n",
    "        layers_nodes_infect_scale = []\n",
    "\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < network_layers_count:\n",
    "            graphs_of_network[i] = nx.Graph()\n",
    "            network_layers_nodes[i] = list(set(network_layers_nodes[i]))\n",
    "            layers_nodes_infect_scale.append({})\n",
    "            if len(network_layers_nodes[i]) > 0:\n",
    "                # graphs_of_network[i].add_nodes_from(network_layers_nodes[i])\n",
    "                graphs_of_network[i].add_edges_from(entra_layer_edges[i])\n",
    "\n",
    "                graphs_of_network[i].graph[\"id\"] = i\n",
    "                graphs_of_network[i].graph[\"node_num\"] = graphs_of_network[i].number_of_nodes()\n",
    "                graphs_of_network[i].graph[\"edge_num\"] = graphs_of_network[i].number_of_edges()\n",
    "\n",
    "                print(colored(\"Layer \"  + str(i) + \": \" + str(graphs_of_network[i].number_of_nodes()) + \" Node And \" +\n",
    "                            str(graphs_of_network[i].number_of_edges()) + \" Edge\", color_list[j]))\n",
    "                # print(colored(graphs_of_network[i].graph['k_shell_info'], color_list[i]))\n",
    "            i += 1\n",
    "            j += 1\n",
    "            if j >= len(color_list):\n",
    "                j = 0\n",
    "\n",
    "        network_entier_nodes_list = []\n",
    "        for item in network_layers_nodes:\n",
    "            network_entier_nodes_list += item\n",
    "            sum_of_layers_nodes += len(item)\n",
    "\n",
    "        network_entier_nodes_list = list(set(network_entier_nodes_list))\n",
    "        network_entier_nodes_count = len(network_entier_nodes_list)\n",
    "        print()\n",
    "        print(\"network entier nodes : \" + colored(str(network_entier_nodes_count), \"yellow\"))\n",
    "        MA_IMMULTI_path = files_handler_obj.make_dir(file_info['path'], 'MA_IMMULTI')\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        pop = 100\n",
    "        maxgen = 50\n",
    "        beta = 0.01\n",
    "        seed_sets = []\n",
    "        for m in range(math.floor(pop/3)):\n",
    "            s_1 = random.sample(network_entier_nodes_list, seed_set_size)\n",
    "            seed_sets.append(sorted(s_1, key=memetic_obj.str_to_int_func))\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        snen_by_synthetic_degree, synthetic_degree_mean, k_top_index  = memetic_obj.sort_networks_entier_nodes_by_synthetic_degree(graphs_of_network, network_entier_nodes_list, seed_set_size)\n",
    "        k_top_synthetic_degree_list = snen_by_synthetic_degree[:(seed_set_size + 1)]\n",
    "        bottom_synthetic_degree_list = snen_by_synthetic_degree[(seed_set_size + 1):]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        for m in range(math.floor(pop/3)):\n",
    "            s_2 = memetic_obj.select_k_nodes_by_synthetic_degree(k_top_synthetic_degree_list, bottom_synthetic_degree_list, seed_set_size)\n",
    "            seed_sets.append(sorted(s_2, key=memetic_obj.str_to_int_func))\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        for m in range(math.ceil(pop/3)):\n",
    "            s_3 = memetic_obj.select_k_nodes_by_highest_degree(k_top_synthetic_degree_list, bottom_synthetic_degree_list,\n",
    "                                                        graphs_of_network, network_entier_nodes_list, seed_set_size)\n",
    "            seed_sets.append(sorted(s_3, key=memetic_obj.str_to_int_func))\n",
    "            \n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        pc = 0.6\n",
    "        new_pc = int(len(seed_sets) * pc)\n",
    "        if new_pc % 2 != 0:\n",
    "            new_pc += 1\n",
    "        pm = 0.4\n",
    "        pl = 0.5\n",
    "        \n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        local_search_candids = random.sample(seed_sets, int(len(seed_sets) * pl))\n",
    "        for gen in local_search_candids:\n",
    "            for item in gen:\n",
    "                if not(item in dict(snen_by_synthetic_degree)):\n",
    "                    print(item)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        for g in range(maxgen):\n",
    "            print(colored(f'Running generation {g+1}th ...', 'light_yellow'))\n",
    "            \n",
    "            print(colored('crossover ...', 'light_blue'))\n",
    "            crossover_candids = random.sample(seed_sets, new_pc)\n",
    "            pbar = tqdm(total=len(crossover_candids))\n",
    "            pbar.unit = ' Gen'\n",
    "            j = 1\n",
    "            while j < len(crossover_candids):\n",
    "                new_gen_a, new_gen_b = Memetic.crossover(crossover_candids[j-1], crossover_candids[j], network_entier_nodes_list)\n",
    "                seed_sets.append(new_gen_a)\n",
    "                seed_sets.append(new_gen_b)\n",
    "                j += 2\n",
    "                if j > len(crossover_candids):\n",
    "                    break\n",
    "                pbar.update(2)\n",
    "            pbar.close()\n",
    "            \n",
    "            print()\n",
    "            print(colored('mutation ...', 'light_red'))\n",
    "            mutation_candids = random.sample(seed_sets, int(len(seed_sets) * pm))\n",
    "            with tqdm(mutation_candids, unit=\" Gen\") as t_gen:\n",
    "                    for gen in t_gen:\n",
    "                        new_gen = Memetic.mutation(gen, snen_by_synthetic_degree,graphs_of_network, seed_set_size)\n",
    "                        seed_sets.append(new_gen)\n",
    "            \n",
    "            print()\n",
    "            print(colored('Local search ...', 'light_green'))\n",
    "            local_search_candids = random.sample(seed_sets, int(len(seed_sets) * pl))\n",
    "            with tqdm(local_search_candids, unit=\" Gen\") as t_gen:\n",
    "                for gen in t_gen:\n",
    "                    new_gen = Memetic.local_search_1(gen, network_entier_nodes_list, graphs_of_network, beta)\n",
    "                    for item in new_gen:\n",
    "                        if not(item in dict(snen_by_synthetic_degree)):\n",
    "                            print(new_gen)\n",
    "                    new_gen = Memetic.local_search_2(new_gen, network_entier_nodes_list, dict(snen_by_synthetic_degree), graphs_of_network)\n",
    "                    seed_sets.append(new_gen)\n",
    "            \n",
    "            print()\n",
    "            print(colored('spreading_approximation ...', 'light_yellow'))\n",
    "            gens_spread_approximation = {}\n",
    "            with tqdm(seed_sets, unit=\" Gen\") as t_gen:\n",
    "                for j, gen in enumerate(t_gen):\n",
    "                    gens_spread_approximation[j] = Memetic.spreading_approximation_multilayer(seed_sets[j],graphs_of_network, beta)\n",
    "\n",
    "            gens_spread_approximation = dict(sorted(gens_spread_approximation.items(), key=lambda item: item[1], reverse=True))\n",
    "            top_gens = []\n",
    "            itr = iter(gens_spread_approximation.items())\n",
    "            for j in range(pop):\n",
    "                top_gens.append(seed_sets[next(itr)[0]])\n",
    "            seed_sets = top_gens\n",
    "            print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        top_10_gens = seed_sets[:10]\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        print(f\"Seed set size: {seed_set_size}\")\n",
    "        beta = 0.01\n",
    "        landa = 0.7\n",
    "        epoch = 10000\n",
    "        SIR_diffusion_model_obj = SIR_Diffusion_Model()\n",
    "        infection = SIR_diffusion_model_obj.synchronous_SIR_multilayer_with_seed_set_model(graphs_of_network, top_10_gens[0], beta, landa, epoch, network_entier_nodes_list)\n",
    "\n",
    "        sir_results_infos = {}\n",
    "        sir_results_infos['infection'] = infection\n",
    "        sir_results_infos['percentage'] = infection / network_entier_nodes_count\n",
    "        sir_results_infos['seed_set'] = top_10_gens[0]\n",
    "\n",
    "        network_infos_writer_obj.write_results_in_file(MA_IMMULTI_path, f'infection k={seed_set_size} beta={beta} landa{landa} epoch{epoch}', sir_results_infos)\n",
    "        print(f\"Network entier nodes count: {network_entier_nodes_count}\")\n",
    "        print(f\"Infected nodes count: {infection}\")\n",
    "        print(f\"Percentage of infection: {sir_results_infos['percentage']}\")\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "        clear_output(wait=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "print('Finished!')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
